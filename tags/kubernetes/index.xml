<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>kubernetes on Fabrice Aneche</title><link>https://blog.nobugware.com/tags/kubernetes/</link><description>Recent content in kubernetes on Fabrice Aneche</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 05 Feb 2024 20:01:00 +0000</lastBuildDate><atom:link href="https://blog.nobugware.com/tags/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>Envoy Gateway In Production</title><link>https://blog.nobugware.com/post/2024/envoy-gateway-in-production/</link><pubDate>Mon, 05 Feb 2024 20:01:00 +0000</pubDate><guid>https://blog.nobugware.com/post/2024/envoy-gateway-in-production/</guid><description>Previous post was about discovering a new offer in the Kubernetes Gateway space Envoy Gateway, in this one I&amp;rsquo;ll share some notes to make it to production.
Envoy Gateway is still rough on the edges, but remember Gateway is mainly a Kubernetes API frontend to provision Envoy Proxy, Envoy Proxy configuration can still be patched to enable a specific feature.
Enable Patching Patching is not enabled by default, create this configmap if you need it:</description></item><item><title>Envoy Gateway a new Gateway API for Kubernetes</title><link>https://blog.nobugware.com/post/2023/envoy-gateway-new-gateway-api-kubernetes/</link><pubDate>Fri, 10 Nov 2023 23:01:00 +0000</pubDate><guid>https://blog.nobugware.com/post/2023/envoy-gateway-new-gateway-api-kubernetes/</guid><description>Envoy Proxy is a well known proxy load balancer offering HTTP, gRPC, TCP, customizable with Lua, Go, WASM &amp;hellip; It&amp;rsquo;s often the core component used to build gateways/proxies for Kubernetes. For example Istio is using it as a proxy load balancer for ingresses but also as a sidecar to create a &amp;ldquo;mesh network&amp;rdquo;.
Envoy Gateway is a more recent project to manage Envoy proxies inside Kubernetes, it is meant to be a common foundation to build on top of it, but it can be used directly as it is.</description></item><item><title>Enabling Cloudflare in front of your Kubernetes cluster with Traefik</title><link>https://blog.nobugware.com/post/enabling-cloudflare-in-front-of-your-kubernetes-cluster-with-traefik/</link><pubDate>Wed, 18 May 2022 04:00:00 +0000</pubDate><guid>https://blog.nobugware.com/post/enabling-cloudflare-in-front-of-your-kubernetes-cluster-with-traefik/</guid><description>I&amp;rsquo;m still using my arm64 4 nodes cluster for experimentation and even to serve some websites. Since I wanted to test some new Cloudflare features, I migrated one of my domain which has a bunch of websites on it.
But first a quick and simple way to serve some static pages:
Serving Static Pages One way is to build an image with the actual pages in it and let Kubernetes serves them.</description></item><item><title>k3s, containerd &amp; ZFS</title><link>https://blog.nobugware.com/post/2019/k3s-containterd-zfs/</link><pubDate>Wed, 18 Dec 2019 18:00:00 +0000</pubDate><guid>https://blog.nobugware.com/post/2019/k3s-containterd-zfs/</guid><description>To simplify distribution k3s does not ship with zfs support.
But can work with by relying on an existing containerd enabled zfs, here is how:
Requierements Install cni-plugins and crictl
Ensure your containerd includes the zfs plugins:
ctr plugins ls ... io.containerd.snapshotter.v1 zfs linux/amd64 ok Configuration Create the default containerd config file
mkdir -p /etc/containerd/ containerd config default &amp;gt; /etc/containerd/config.toml Change the snapshotter to &amp;quot;zfs&amp;quot;
[plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.containerd] snapshotter = &amp;quot;zfs&amp;quot; And in my special Arch case also change the path to the cni binaries:</description></item><item><title>Nomad an alternative to Kubernetes</title><link>https://blog.nobugware.com/post/2019/nomad_an_alternative_to_kubernetes/</link><pubDate>Tue, 12 Nov 2019 03:00:00 +0000</pubDate><guid>https://blog.nobugware.com/post/2019/nomad_an_alternative_to_kubernetes/</guid><description>If you are familiar with this blog you know I really appreciate Kubernetes: as a former ops I strongly believe Kubernetes is one way to bundle &amp;ldquo;the sum of 20y ops good practices&amp;rdquo;.
But there are others solutions one is Nomad.
It&amp;rsquo;s made by Hashicorp, creators of Vault, Consul, Terraform&amp;hellip;
In general Hashicorp is synonym with quality.
Nomad is a task scheduler, a task could be execute a command, run a Docker container or a QEMU vm&amp;hellip;</description></item><item><title>Advanced Traefik 2.0 with Kubernetes</title><link>https://blog.nobugware.com/post/2019/advanced-traefik-2-0-with-kubernetes/</link><pubDate>Mon, 07 Oct 2019 00:00:00 -0400</pubDate><guid>https://blog.nobugware.com/post/2019/advanced-traefik-2-0-with-kubernetes/</guid><description>Following my earlier post about Traefik 2 and Kubernetes, here are some advanced configuration examples and a full yaml example at the end of this post:
Protecting a route with a password Create an htpasswd file named users for a user admin
htpasswd -c users admin Use kubectl to create the secret (easier for multi lines file).
kubectl create secret generic admin-authsecret --from-file=users Create a middleware for authentication:</description></item><item><title>Google Kubernetes Engine &amp; GCP</title><link>https://blog.nobugware.com/post/2019/google-kubernetes-engine-gcp/</link><pubDate>Mon, 30 Sep 2019 00:00:00 -0400</pubDate><guid>https://blog.nobugware.com/post/2019/google-kubernetes-engine-gcp/</guid><description>I&amp;rsquo;ve been using Google Compute Platform (GCP) &amp;amp; Google Kubernetes Engine (GKE) for years.
And I love it, I hated AWS since the first release to these days, naming is cumbersome, UX is terrible&amp;hellip;
Here are a quick survey of the tools and how I&amp;rsquo;ve used them for small to medium projects:
Cloud Build Cloud Build is super easy, it&amp;rsquo;s a scriptable CI/CD, very similar to Github Actions, there is a one hour free tier per day, the default machine is very slow, it can be tuned in the cloudbuild.</description></item><item><title>Traefik 2.0 with Kubernetes</title><link>https://blog.nobugware.com/post/2019/traefik-2-0-with-kubernetes/</link><pubDate>Tue, 17 Sep 2019 00:00:00 -0400</pubDate><guid>https://blog.nobugware.com/post/2019/traefik-2-0-with-kubernetes/</guid><description>Traefik 2.0 is here !
Traefik is a reverse proxy load balancer (and more), it can learn the routes to respond to by discovering them in multiple providers, Docker, Kubernetes &amp;hellip;
Traefik v1.x is very stable, v2.x is fresh new tech, with breaking changes and unfinished documentation, so test it first.
From Traefik&amp;rsquo;s documentation:
Providers discover the services that live on your infrastructure (their IP, health, &amp;hellip;) Entrypoints listen for incoming traffic (ports, &amp;hellip;) Routers analyze the requests (host, path, headers, SSL, &amp;hellip;) Services forward the request to your services (load balancing, &amp;hellip;) Middlewares may update the request or make decisions based on the request (authentication, rate limiting, headers, &amp;hellip;) Kubernetes In Traefik v1, Kubernetes ingress were used to discover the routes:</description></item><item><title>Access Kubernetes Web Interfaces from the Outside</title><link>https://blog.nobugware.com/post/2019/access-web-interface/</link><pubDate>Mon, 09 Sep 2019 13:00:00 -0400</pubDate><guid>https://blog.nobugware.com/post/2019/access-web-interface/</guid><description>Here is a simple yet useful trick to access web interface within your cluster.
As stated in the Kubernetes documentation you can use kubectl proxy.
I&amp;rsquo;ve seen a lot of people using the proxy to access the dashboard but you can use it to access any web interfaces, without the need to create an ingress and protect it, especially useful in dev environment.
http://kubernetes_master_address/api/v1/namespaces/namespace_name/services/service_name[:port_name]/proxy For example here is how to access the Traefik dashboard described as follow:</description></item><item><title>Bare Metal Kubernetes Quick Installation Arm64 &amp; Arch</title><link>https://blog.nobugware.com/post/2019/bare-metal-kubernetes-quick-installations-on-arch/</link><pubDate>Mon, 09 Sep 2019 00:02:00 -0400</pubDate><guid>https://blog.nobugware.com/post/2019/bare-metal-kubernetes-quick-installations-on-arch/</guid><description>I&amp;rsquo;m still playing with my 3 nodes arm64 cluster, having some stability issues with k3s, I turned into kubeadm to deploy a bare metal non HA one master two workers Kubernetes cluster.
My host is Arch which is theoretically not supported but still works.
Required tasks sudo pacman -S ethtool ebtables socat cni-plugins Install aur/kubelet-bin and aur/kubeadm-bin
I needed a private registry to host my images, on master node:</description></item><item><title>k3s on arm64</title><link>https://blog.nobugware.com/post/2019/k3s-on-arm64/</link><pubDate>Wed, 19 Jun 2019 06:00:00 -0400</pubDate><guid>https://blog.nobugware.com/post/2019/k3s-on-arm64/</guid><description>I&amp;rsquo;m evaluating k3s a Lightweight Kubernetes on a 3 nodes arm64 cluster (RK3328 Quad arm64).
At the time of writing the stable release is k3s v0.6.1.
Here are my notes:
If you haven&amp;rsquo;t installed k3s with the install.sh, you may need to load some modules: br_netfilter and overlay
Docker is not needed since k3s is using containerd but it seems I had to start docker to initialized the whole cgroups, at least on Arch</description></item><item><title>Deploying a website with Caddy, Git and Kubernetes</title><link>https://blog.nobugware.com/post/2019/deploying-a-website-with-caddy-git-and-kubernetes/</link><pubDate>Sat, 27 Apr 2019 02:01:00 -0400</pubDate><guid>https://blog.nobugware.com/post/2019/deploying-a-website-with-caddy-git-and-kubernetes/</guid><description>Caddy is the swiss army of the web server, and with the recent commercial license changes, it&amp;rsquo;s time to give it some love back.
I have several static websites, some generated with Hugo, some are plain HTML.
I wanted a small container, to run it inside a Kubernetes cluster, capable of pulling some git repos and serve them.
Caddy-git Caddy is already capable of that with the help of caddy-git unfortunately it is only working with ssh keys.</description></item><item><title>gRPC Load Balancing inside Kubernetes</title><link>https://blog.nobugware.com/post/2019/kubernetes_mesh_network_load_balancing_grpc_services/</link><pubDate>Mon, 11 Mar 2019 00:32:43 -0500</pubDate><guid>https://blog.nobugware.com/post/2019/kubernetes_mesh_network_load_balancing_grpc_services/</guid><description>Context I wanted to blog about this for years: how to connect to a Kubernete&amp;rsquo;s loadbalanced service?
How to deal with disconnections/re-connections, maintenance? What about gRPC specifically?
The answer is heavily connected to the network stack used by Kubernetes, but with the &amp;ldquo;Mesh Network&amp;rdquo; revolution, It&amp;rsquo;s not always clear how it works anymore and what the options are. How it works First I recommend you to watch this great yet simple video: Container Networking From Scratch, then the Services clusterIP documentation.</description></item><item><title>Traefik gRPC Load Balancing and Traces Propagation</title><link>https://blog.nobugware.com/post/2019/traefik_load_balancing_grpc_services_trace_propagation/</link><pubDate>Mon, 04 Mar 2019 04:32:43 +0000</pubDate><guid>https://blog.nobugware.com/post/2019/traefik_load_balancing_grpc_services_trace_propagation/</guid><description>Following my recent blog post on setting up a dev environment in Kubernetes, here are some tips to use Traefik as a gRPC load balancer.
Traefik can be used on the edge and route incoming HTTP traffic to your Kubernetes cluster, but it&amp;rsquo;s also supporting gRPC.
gRPC Load Balancing with Traefik Here I have a gRPC service I want to expose on the edge.
apiVersion: v1 kind: Service metadata: name: myapp labels: name: &amp;#34;myapp&amp;#34; type: &amp;#34;grpc&amp;#34; spec: ports: - port: 9200 name: &amp;#34;grpc&amp;#34; targetPort: grpc protocol: TCP selector: app: &amp;#34;myapp&amp;#34; clusterIP: None Note the clusterIP: None, it&amp;rsquo;s a headless service.</description></item><item><title>Kubernetes Quick Setup with Prometheus, Grafana &amp; Jaeger</title><link>https://blog.nobugware.com/post/2019/kubernetes_quick_development_setup_minikube_prometheus_grafana/</link><pubDate>Thu, 21 Feb 2019 00:19:57 -0200</pubDate><guid>https://blog.nobugware.com/post/2019/kubernetes_quick_development_setup_minikube_prometheus_grafana/</guid><description>Introduction When starting on a new project or prototyping on a new idea, I find myself doing the same tasks again and again. Thanks to Kubernetes it&amp;rsquo;s possible to setup a new env from scratch really fast.
Here is a quick setup (mostly notes) to create a dev environment using Minikube and the workflow I&amp;rsquo;m using with it.
Not knowing in advance where this future project will be hosted, I try to stay platform agnostic.</description></item></channel></rss>